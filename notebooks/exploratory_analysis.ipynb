{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{ “cells”: \\[ { “cell_type”: “markdown”, “id”: “fraud-analysis-title”,\n",
    "“metadata”: {}, “source”: \\[ “\\# Fraud Detection - Exploratory Data\n",
    "Analysis”, “”, “This notebook provides exploratory data analysis for the\n",
    "fraud detection system.”, “”, “\\## Contents”, “1. Data Loading and\n",
    "Overview”, “2. Fraud Distribution Analysis”, “3. Feature Analysis”, “4.\n",
    "Transaction Patterns”, “5. Model Performance Analysis” \\] }, {\n",
    "“cell_type”: “code”, “execution_count”: null, “id”: “imports”,\n",
    "“metadata”: {}, “outputs”: \\[\\], “source”: \\[ “import pandas as pd”,\n",
    "“import numpy as np”, “import matplotlib.pyplot as plt”, “import seaborn\n",
    "as sns”, “import plotly.express as px”, “import plotly.graph_objects as\n",
    "go”, “from plotly.subplots import make_subplots”, “”, “\\# Set style”,\n",
    "“plt.style.use(‘seaborn-v0_8’)”, “sns.set_palette(\"husl\")”, “”, “\\#\n",
    "Configure pandas display”, “pd.set_option(‘display.max_columns’, None)”,\n",
    "“pd.set_option(‘display.width’, None)”, “”, “print(\"✅ Imports\n",
    "successful\")” \\] }, { “cell_type”: “markdown”, “id”: “data-loading”,\n",
    "“metadata”: {}, “source”: \\[ “\\## 1. Data Loading and Overview” \\] }, {\n",
    "“cell_type”: “code”, “execution_count”: null, “id”: “load-data”,\n",
    "“metadata”: {}, “outputs”: \\[\\], “source”: \\[ “\\# Generate sample data\n",
    "if no data file exists”, “import sys”, “sys.path.append(‘../src’)”, “”,\n",
    "“from data.data_generator import FraudDataGenerator”, “”, “\\# Generate\n",
    "synthetic data”, “generator = FraudDataGenerator(seed=42)”, “df =\n",
    "generator.generate_dataset(n_samples=10000, n_users=1000)”, “”,\n",
    "“print(f\"Dataset shape: {df.shape}\")”, “print(f\"Fraud rate:\n",
    "{df\\[‘is_fraud’\\].mean():.3%}\")”, “”, “df.head()” \\] }, { “cell_type”:\n",
    "“code”, “execution_count”: null, “id”: “data-info”, “metadata”: {},\n",
    "“outputs”: \\[\\], “source”: \\[ “\\# Dataset information”, “print(\"Dataset\n",
    "Info:\")”, “print(f\"Total transactions: {len(df):,}\")”, “print(f\"Unique\n",
    "users: {df\\[‘user_id’\\].nunique():,}\")”, “print(f\"Unique merchants:\n",
    "{df\\[‘merchant_id’\\].nunique():,}\")”, “print(f\"Date range:\n",
    "{df\\[‘timestamp’\\].min()} to {df\\[‘timestamp’\\].max()}\")”, “”, “\\#\n",
    "Missing values”, “print(\"\\nMissing values:\")”,\n",
    "“print(df.isnull().sum())” \\] }, { “cell_type”: “markdown”, “id”:\n",
    "“fraud-distribution”, “metadata”: {}, “source”: \\[ “\\## 2. Fraud\n",
    "Distribution Analysis” \\] }, { “cell_type”: “code”, “execution_count”:\n",
    "null, “id”: “fraud-overview”, “metadata”: {}, “outputs”: \\[\\], “source”:\n",
    "\\[ “\\# Fraud distribution”, “fraud_counts =\n",
    "df\\[‘is_fraud’\\].value_counts()”, “fraud_pct =\n",
    "df\\[‘is_fraud’\\].value_counts(normalize=True) \\* 100”, “”, “fig, (ax1,\n",
    "ax2) = plt.subplots(1, 2, figsize=(15, 5))”, “”, “\\# Count plot”,\n",
    "“fraud_counts.plot(kind=‘bar’, ax=ax1, color=\\[‘green’, ‘red’\\])”,\n",
    "“ax1.set_title(‘Fraud Distribution (Count)’)”, “ax1.set_xlabel(‘Is\n",
    "Fraud’)”, “ax1.set_ylabel(‘Count’)”, “ax1.set_xticklabels(\\[‘Normal’,\n",
    "‘Fraud’\\], rotation=0)”, “”, “\\# Percentage pie chart”,\n",
    "“ax2.pie(fraud_pct.values, labels=\\[‘Normal’, ‘Fraud’\\],\n",
    "autopct=‘%1.2f%%’, ”, ” colors=\\[‘green’,\n",
    "‘red’\\])“,”ax2.set_title(‘Fraud Distribution\n",
    "(Percentage)’)“,”“,”plt.tight_layout()“,”plt.show()“,”“,”print(f\"Normal\n",
    "transactions: {fraud_counts\\[0\\]:,}\n",
    "({fraud_pct\\[0\\]:.2f}%)\")“,”print(f\"Fraudulent transactions:\n",
    "{fraud_counts\\[1\\]:,} ({fraud_pct\\[1\\]:.2f}%)\")” \\] }, { “cell_type”:\n",
    "“markdown”, “id”: “feature-analysis”, “metadata”: {}, “source”: \\[ “\\##\n",
    "3. Feature Analysis” \\] }, { “cell_type”: “code”, “execution_count”:\n",
    "null, “id”: “amount-analysis”, “metadata”: {}, “outputs”: \\[\\],\n",
    "“source”: \\[ “\\# Amount analysis”, “fig, axes = plt.subplots(2, 2,\n",
    "figsize=(15, 12))”, “”, “\\# Amount distribution by fraud status”,\n",
    "“df.boxplot(column=‘amount’, by=‘is_fraud’, ax=axes\\[0,0\\])”,\n",
    "“axes\\[0,0\\].set_title(‘Amount Distribution by Fraud Status’)”,\n",
    "“axes\\[0,0\\].set_xlabel(‘Is Fraud’)”, “”, “\\# Log amount distribution”,\n",
    "“df\\[‘log_amount’\\] = np.log1p(df\\[‘amount’\\])”,\n",
    "“axes\\[0,1\\].hist(df\\[df\\[‘is_fraud’\\]==0\\]\\[‘log_amount’\\], alpha=0.7,\n",
    "label=‘Normal’, bins=50)”,\n",
    "“axes\\[0,1\\].hist(df\\[df\\[‘is_fraud’\\]==1\\]\\[‘log_amount’\\], alpha=0.7,\n",
    "label=‘Fraud’, bins=50)”, “axes\\[0,1\\].set_title(‘Log Amount\n",
    "Distribution’)”, “axes\\[0,1\\].legend()”, “”, “\\# Amount by merchant\n",
    "category”, “category_fraud =\n",
    "df.groupby(‘merchant_category’)\\[‘is_fraud’\\].agg(\\[‘count’, ‘mean’\\])”,\n",
    "“category_fraud.columns = \\[‘transaction_count’, ‘fraud_rate’\\]”,\n",
    "“category_fraud = category_fraud.sort_values(‘fraud_rate’,\n",
    "ascending=False)”, “”, “category_fraud\\[‘fraud_rate’\\].plot(kind=‘bar’,\n",
    "ax=axes\\[1,0\\])”, “axes\\[1,0\\].set_title(‘Fraud Rate by Merchant\n",
    "Category’)”, “axes\\[1,0\\].set_ylabel(‘Fraud Rate’)”,\n",
    "“axes\\[1,0\\].tick_params(axis=‘x’, rotation=45)”, “”, “\\# Amount\n",
    "statistics”, “amount_stats =\n",
    "df.groupby(‘is_fraud’)\\[‘amount’\\].describe()”,\n",
    "“axes\\[1,1\\].axis(‘off’)”,\n",
    "“axes\\[1,1\\].table(cellText=amount_stats.round(2).values,”, ”\n",
    "rowLabels=\\[‘Normal’, ‘Fraud’\\],“,” colLabels=amount_stats.columns,“,”\n",
    "cellLoc=‘center’,“,” loc=‘center’)“,”axes\\[1,1\\].set_title(‘Amount\n",
    "Statistics by Fraud Status’)“,”“,”plt.tight_layout()“,”plt.show()” \\] },\n",
    "{ “cell_type”: “code”, “execution_count”: null, “id”:\n",
    "“temporal-analysis”, “metadata”: {}, “outputs”: \\[\\], “source”: \\[ “\\#\n",
    "Temporal analysis”, “df\\[‘timestamp’\\] =\n",
    "pd.to_datetime(df\\[‘timestamp’\\])”, “df\\[‘hour’\\] =\n",
    "df\\[‘timestamp’\\].dt.hour”, “df\\[‘day_of_week’\\] =\n",
    "df\\[‘timestamp’\\].dt.day_name()”, “df\\[‘is_weekend’\\] =\n",
    "df\\[‘timestamp’\\].dt.dayofweek \\>= 5”, “”, “fig, axes = plt.subplots(2,\n",
    "2, figsize=(15, 12))”, “”, “\\# Fraud rate by hour”, “hourly_fraud =\n",
    "df.groupby(‘hour’)\\[‘is_fraud’\\].mean()”,\n",
    "“hourly_fraud.plot(kind=‘line’, marker=‘o’, ax=axes\\[0,0\\])”,\n",
    "“axes\\[0,0\\].set_title(‘Fraud Rate by Hour of Day’)”,\n",
    "“axes\\[0,0\\].set_xlabel(‘Hour’)”, “axes\\[0,0\\].set_ylabel(‘Fraud\n",
    "Rate’)”, “axes\\[0,0\\].grid(True)”, “”, “\\# Fraud rate by day of week”,\n",
    "“day_order = \\[‘Monday’, ‘Tuesday’, ‘Wednesday’, ‘Thursday’, ‘Friday’,\n",
    "‘Saturday’, ‘Sunday’\\]”, “daily_fraud =\n",
    "df.groupby(‘day_of_week’)\\[‘is_fraud’\\].mean().reindex(day_order)”,\n",
    "“daily_fraud.plot(kind=‘bar’, ax=axes\\[0,1\\])”,\n",
    "“axes\\[0,1\\].set_title(‘Fraud Rate by Day of Week’)”,\n",
    "“axes\\[0,1\\].set_xlabel(‘Day of Week’)”, “axes\\[0,1\\].set_ylabel(‘Fraud\n",
    "Rate’)”, “axes\\[0,1\\].tick_params(axis=‘x’, rotation=45)”, “”, “\\#\n",
    "Weekend vs weekday”, “weekend_fraud =\n",
    "df.groupby(‘is_weekend’)\\[‘is_fraud’\\].mean()”,\n",
    "“weekend_fraud.plot(kind=‘bar’, ax=axes\\[1,0\\])”,\n",
    "“axes\\[1,0\\].set_title(‘Fraud Rate: Weekend vs Weekday’)”,\n",
    "“axes\\[1,0\\].set_xlabel(‘Is Weekend’)”,\n",
    "“axes\\[1,0\\].set_xticklabels(\\[‘Weekday’, ‘Weekend’\\], rotation=0)”, “”,\n",
    "“\\# Transaction volume by hour”, “hourly_volume =\n",
    "df.groupby(‘hour’).size()”, “hourly_volume.plot(kind=‘bar’,\n",
    "ax=axes\\[1,1\\], alpha=0.7)”, “axes\\[1,1\\].set_title(‘Transaction Volume\n",
    "by Hour’)”, “axes\\[1,1\\].set_xlabel(‘Hour’)”,\n",
    "“axes\\[1,1\\].set_ylabel(‘Transaction Count’)”, “”, “plt.tight_layout()”,\n",
    "“plt.show()” \\] }, { “cell_type”: “markdown”, “id”:\n",
    "“geographic-analysis”, “metadata”: {}, “source”: \\[ “\\## 4. Geographic\n",
    "Analysis” \\] }, { “cell_type”: “code”, “execution_count”: null, “id”:\n",
    "“location-analysis”, “metadata”: {}, “outputs”: \\[\\], “source”: \\[ “\\#\n",
    "Extract location data”, “df\\[‘lat’\\] = df\\[‘location’\\].apply(lambda x:\n",
    "x.get(‘lat’, 0) if isinstance(x, dict) else 0)”, “df\\[‘lon’\\] =\n",
    "df\\[‘location’\\].apply(lambda x: x.get(‘lon’, 0) if isinstance(x, dict)\n",
    "else 0)”, “”, “\\# Create interactive map using plotly”, “fig =\n",
    "px.scatter_mapbox(”, ” df.sample(1000), \\# Sample for performance“,”\n",
    "lat=\"lat\", “,” lon=\"lon\",“,” color=\"is_fraud\",“,” color_discrete_map={0:\n",
    "‘green’, 1: ‘red’},“,” hover_data=\\[\"amount\", \"merchant_category\"\\],“,”\n",
    "mapbox_style=\"open-street-map\",“,” title=\"Transaction Locations\n",
    "(Sample)\",“,”\n",
    "height=600“,”)“,”“,”fig.update_layout(margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0})“,”fig.show()”\n",
    "\\] }, { “cell_type”: “markdown”, “id”: “correlation-analysis”,\n",
    "“metadata”: {}, “source”: \\[ “\\## 5. Correlation Analysis” \\] }, {\n",
    "“cell_type”: “code”, “execution_count”: null, “id”: “correlations”,\n",
    "“metadata”: {}, “outputs”: \\[\\], “source”: \\[ “\\# Feature engineering\n",
    "for correlation analysis”, “from features.feature_engineer import\n",
    "FeatureEngineer”, “”, “engineer = FeatureEngineer()”, “features_df =\n",
    "engineer.create_features(df)”, “”, “\\# Select numeric features for\n",
    "correlation”, “numeric_features =\n",
    "features_df.select_dtypes(include=\\[np.number\\]).columns”,\n",
    "“correlation_matrix = features_df\\[numeric_features\\].corr()”, “”, “\\#\n",
    "Plot correlation heatmap”, “plt.figure(figsize=(20, 16))”, “mask =\n",
    "np.triu(np.ones_like(correlation_matrix, dtype=bool))”,\n",
    "“sns.heatmap(correlation_matrix, mask=mask, annot=False,\n",
    "cmap=‘coolwarm’, center=0)”, “plt.title(‘Feature Correlation Matrix’)”,\n",
    "“plt.tight_layout()”, “plt.show()”, “”, “\\# Top correlations with\n",
    "fraud”, “if ‘is_fraud’ in correlation_matrix.columns:”, ”\n",
    "fraud_correlations =\n",
    "correlation_matrix\\[‘is_fraud’\\].abs().sort_values(ascending=False)“,”\n",
    "print(\"Top 15 features correlated with fraud:\")“,”\n",
    "print(fraud_correlations.head(15))” \\] }, { “cell_type”: “markdown”,\n",
    "“id”: “model-analysis”, “metadata”: {}, “source”: \\[ “\\## 6. Model\n",
    "Performance Analysis” \\] }, { “cell_type”: “code”, “execution_count”:\n",
    "null, “id”: “model-performance”, “metadata”: {}, “outputs”: \\[\\],\n",
    "“source”: \\[ “\\# Train a simple model for analysis”, “from\n",
    "sklearn.model_selection import train_test_split”, “from sklearn.ensemble\n",
    "import RandomForestClassifier”, “from sklearn.metrics import\n",
    "classification_report, roc_curve, precision_recall_curve”, “”, “\\#\n",
    "Prepare data”, “X =\n",
    "features_df.select_dtypes(include=\\[np.number\\]).fillna(0)”, “y =\n",
    "df\\[‘is_fraud’\\]”, “”, “\\# Remove target from features if present”, “if\n",
    "‘is_fraud’ in X.columns:”, ” X = X.drop(‘is_fraud’,\n",
    "axis=1)“,”“,”X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "test_size=0.2, random_state=42, stratify=y)“,”“,”\\# Train model“,”model\n",
    "= RandomForestClassifier(n_estimators=100,\n",
    "random_state=42)“,”model.fit(X_train, y_train)“,”“,”\\#\n",
    "Predictions“,”y_pred = model.predict(X_test) y_pred_proba =\n",
    "model.predict_proba(X_test)\\[:, 1\\]\n",
    "\n",
    "print(“Classification Report:”) print(classification_report(y_test,\n",
    "y_pred))\n",
    "\n",
    "# Performance plots\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# ROC Curve\n",
    "\n",
    "fpr, tpr, \\_ = roc_curve(y_test, y_pred_proba) roc_auc =\n",
    "roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "axes\\[0,0\\].plot(fpr, tpr, color=‘darkorange’, lw=2, label=f’ROC curve\n",
    "(AUC = {roc_auc:.3f})‘) axes\\[0,0\\].plot(\\[0, 1\\], \\[0, 1\\],\n",
    "color=’navy’, lw=2, linestyle=‘–’) axes\\[0,0\\].set_xlabel(‘False\n",
    "Positive Rate’) axes\\[0,0\\].set_ylabel(‘True Positive Rate’)\n",
    "axes\\[0,0\\].set_title(‘ROC Curve’) axes\\[0,0\\].legend()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "\n",
    "precision, recall, \\_ = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "axes\\[0,1\\].plot(recall, precision, color=‘blue’, lw=2, label=f’PR curve\n",
    "(AUC = {pr_auc:.3f})‘) axes\\[0,1\\].set_xlabel(’Recall’)\n",
    "axes\\[0,1\\].set_ylabel(‘Precision’)\n",
    "axes\\[0,1\\].set_title(‘Precision-Recall Curve’) axes\\[0,1\\].legend()\n",
    "\n",
    "# Feature Importance\n",
    "\n",
    "feature_importance = pd.Series(model.feature_importances\\_,\n",
    "index=X.columns).sort_values(ascending=False)\n",
    "feature_importance.head(15).plot(kind=‘barh’, ax=axes\\[1,0\\])\n",
    "axes\\[1,0\\].set_title(‘Top 15 Feature Importances’)\n",
    "\n",
    "# Prediction Distribution\n",
    "\n",
    "axes\\[1,1\\].hist(y_pred_proba\\[y_test==0\\], bins=50, alpha=0.7,\n",
    "label=‘Normal’, color=‘green’)\n",
    "axes\\[1,1\\].hist(y_pred_proba\\[y_test==1\\], bins=50, alpha=0.7,\n",
    "label=‘Fraud’, color=‘red’) axes\\[1,1\\].set_xlabel(‘Predicted\n",
    "Probability’) axes\\[1,1\\].set_ylabel(‘Frequency’)\n",
    "axes\\[1,1\\].set_title(‘Prediction Distribution’) axes\\[1,1\\].legend()\n",
    "\n",
    "plt.tight_layout() plt.show()\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")(f\"ROC AUC: {roc_auc:.4f}\")(f\"PR\n",
    "AUC: {pr_auc:.4f}\")(f\"Precision: {precision_score(y_test,\n",
    "y_pred):.4f}\")(f\"Recall: {recall_score(y_test, y_pred):.4f}\")” \\] }, {\n",
    "“cell_type”: “markdown”, “id”: “business-impact”, “metadata”: {},\n",
    "“source”: \\[ “\\## 7. Business Impact Analysis” \\] }, { “cell_type”:\n",
    "“code”, “execution_count”: null, “id”: “business-metrics”, “metadata”:\n",
    "{}, “outputs”: \\[\\], “source”: \\[ “\\# Calculate business metrics”,\n",
    "“total_fraud_amount = df\\[df\\[‘is_fraud’\\] == 1\\]\\[‘amount’\\].sum()”,\n",
    "“avg_fraud_amount = df\\[df\\[‘is_fraud’\\] == 1\\]\\[‘amount’\\].mean()”,\n",
    "“avg_normal_amount = df\\[df\\[‘is_fraud’\\] == 0\\]\\[‘amount’\\].mean()”,\n",
    "“”, “print(\"Business Impact Metrics:\")”, “print(f\"Total fraudulent\n",
    "amount: \\${total_fraud_amount:,.2f}\")”, “print(f\"Average fraud\n",
    "transaction: \\${avg_fraud_amount:.2f}\")”, “print(f\"Average normal\n",
    "transaction: \\${avg_normal_amount:.2f}\")”, “print(f\"Fraud amount vs\n",
    "normal ratio: {avg_fraud_amount/avg_normal_amount:.2f}x\")”, “”, “\\#\n",
    "Model savings calculation”, “if len(y_test) \\> 0:”, ” detected_fraud =\n",
    "sum((y_test == 1) & (y_pred == 1))“,” missed_fraud = sum((y_test == 1) &\n",
    "(y_pred == 0))“,” false_alarms = sum((y_test == 0) & (y_pred == 1))“,”\n",
    "“,” \\# Estimate savings (assuming we catch detected fraud)“,”\n",
    "estimated_savings = detected_fraud \\* avg_fraud_amount“,”\n",
    "estimated_losses = missed_fraud \\* avg_fraud_amount“,” “,”\n",
    "print(f\"\\nModel Impact (on test set):\")“,” print(f\"Fraud transactions\n",
    "detected: {detected_fraud}\")“,” print(f\"Fraud transactions missed:\n",
    "{missed_fraud}\")“,” print(f\"False alarms: {false_alarms}\")“,”\n",
    "print(f\"Estimated fraud prevented: \\${estimated_savings:,.2f}\")“,”\n",
    "print(f\"Estimated losses (missed): \\${estimated_losses:,.2f}\")” \\] }, {\n",
    "“cell_type”: “markdown”, “id”: “recommendations”, “metadata”: {},\n",
    "“source”: \\[ “\\## 8. Key Insights and Recommendations” \\] }, {\n",
    "“cell_type”: “markdown”, “id”: “insights”, “metadata”: {}, “source”: \\[\n",
    "“\\### Key Insights:”, “”, “1. **Fraud Pattern**: Fraudulent transactions\n",
    "show distinct patterns in:”, ” - Higher average amounts“,” - Specific\n",
    "time periods (night/weekend)“,” - Certain merchant categories“,” -\n",
    "Geographic clustering“,”“,”2. **Model Performance**: “,” - Achieves good\n",
    "separation between fraud and normal transactions“,” - Feature importance\n",
    "shows amount-based and behavioral features are key“,” - Precision-recall\n",
    "trade-off needs business consideration“,”“,”3. **Business Impact**:“,” -\n",
    "Significant financial exposure from fraud“,” - Model can prevent\n",
    "substantial losses“,” - False positives impact customer\n",
    "experience“,”“,”\\### Recommendations:“,”“,”1. **Feature\n",
    "Enhancement**:“,” - Add more behavioral features (velocity,\n",
    "patterns)“,” - Include network analysis (merchant/user connections)“,” -\n",
    "Enhance location-based features“,”“,”2. **Model Improvements**:“,” -\n",
    "Ensemble methods for better performance“,” - Regular retraining with new\n",
    "data“,” - Threshold optimization for business objectives“,”“,”3.\n",
    "**Operational**:“,” - Real-time monitoring dashboard“,” - Alert system\n",
    "for high-risk transactions“,” - Feedback loop for model\n",
    "improvement“,”“,”4. **Business Rules**:“,” - Risk-based transaction\n",
    "limits“,” - Enhanced verification for high-risk transactions“,” -\n",
    "Customer communication for false positives” \\] }, { “cell_type”: “code”,\n",
    "“execution_count”: null, “id”: “save-results”, “metadata”: {},\n",
    "“outputs”: \\[\\], “source”: \\[ “\\# Save analysis results”, “import os”,\n",
    "“”, “\\# Create reports directory”, “os.makedirs(‘../reports’,\n",
    "exist_ok=True)”, “”, “\\# Save key metrics”, “analysis_summary = {”, ”\n",
    "‘dataset_size’: len(df),“,” ‘fraud_rate’: df\\[‘is_fraud’\\].mean(),“,”\n",
    "‘total_fraud_amount’: total_fraud_amount,“,” ‘avg_fraud_amount’:\n",
    "avg_fraud_amount,“,” ‘model_roc_auc’: roc_auc if ‘roc_auc’ in locals()\n",
    "else None,“,” ‘model_pr_auc’: pr_auc if ‘pr_auc’ in locals() else\n",
    "None“,”}“,”“,”\\# Save to JSON“,”import json“,”with\n",
    "open(‘../reports/eda_summary.json’, ‘w’) as f:“,”\n",
    "json.dump(analysis_summary, f, indent=2, default=str)“,”“,”\\# Save\n",
    "feature importance“,”if ‘feature_importance’ in locals():“,”\n",
    "feature_importance.to_csv(‘../reports/feature_importance.csv’)“,”“,”print(\"✅\n",
    "Analysis results saved to reports/ directory\")” \\] } \\], “metadata”: {\n",
    "“kernelspec”: { “display_name”: “Python 3 (ipykernel)”, “language”:\n",
    "“python”, “name”: “python3” }, “language_info”: { “codemirror_mode”: {\n",
    "“name”: “ipython”, “version”: 3 }, “file_extension”: “.py”, “mimetype”:\n",
    "“text/x-python”, “name”: “python”, “nbconvert_exporter”: “python”,\n",
    "“pygments_lexer”: “ipython3”, “version”: “3.9.18” } }, “nbformat”: 4,\n",
    "“nbformat_minor”: 5 }"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
